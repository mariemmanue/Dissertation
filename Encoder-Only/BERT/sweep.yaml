program: train.py
name: bert-aae-sweep-v2
project: aae-ddm-modernbert
method: bayes

metric:
  name: eval_f1
  goal: maximize

parameters:
  encoder:
    values: ["modernbert"]  # which base encoder to use
  learning_rate:
    distribution: log_uniform_values
    min: 5e-6
    max: 2e-5
  batch_size:
    values: [32]
  epochs:
    values: [4, 5, 6]
  warmup_steps:
    values: [300, 800]
  max_length:
    values: [256]
  weight_decay:
    distribution: uniform
    min: 0.0
    max: 0.1

command:
  - /nlp/scr/mtano/miniconda3/envs/cgedit/bin/python
  - train.py
  - CGEdit
  - AAE
  - --wandb_project=aae-ddm-modernbert
  - --encoder
  - ${encoder}
